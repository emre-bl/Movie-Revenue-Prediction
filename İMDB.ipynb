{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_since(year):\n",
    "    import pandas as pd\n",
    "    year_data = pd.read_csv('year.csv', on_bad_lines='skip', sep=\"\\t\")\n",
    "    movie_data = year_data[year_data[\"titleType\"].isin([\"movie\", \"tvMovie\"])]\n",
    "    movie_data_with_year = movie_data[movie_data[\"startYear\"] >= \"1990\"]\n",
    "    movie_data_with_valid_year = movie_data_with_year[movie_data_with_year[\"startYear\"] != \"\\\\N\"]\n",
    "    movie_data_with_valid_year = movie_data_with_valid_year[[\"tconst\", \"startYear\", \"originalTitle\"]]\n",
    "\n",
    "    imdb_data = pd.read_csv(\"ratings.csv\", sep=\"\\t\")\n",
    "\n",
    "    year_vote_data = pd.merge(imdb_data, movie_data_with_valid_year, on=\"tconst\", how=\"right\")\n",
    "    year_vote_data = year_vote_data[[\"tconst\",\"startYear\",\"averageRating\",\"numVotes\", \"originalTitle\"]]\n",
    "    year_vote_data.columns = [\"title id\",\"Year\",\"Rating\",\"Votes\", \"Title\"]\n",
    "    year_vote_data[\"rating link\"] = \"https://www.imdb.com/title/\"+year_vote_data[\"title id\"]+\"/ratings/?ref_=tt_ov_rt\"\n",
    "    year_vote_data = year_vote_data.sort_values(by=\"title id\").reset_index(drop=True)\n",
    "    year_vote_data.to_csv(\"movies_since_\"+\"1990\"+\".csv\", index=False)\n",
    "\n",
    "    return year_vote_data\n",
    "dataset = get_movies_since(\"1990\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting vote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_votes(link, vote_threshold=10000):\n",
    "    import requests, re\n",
    "    request_text = requests.get(link).text\n",
    "    if \"No Ratings Available\" in request_text or \"Well, what if there is no webpage?\" in request_text or int(((request_text[request_text.index(\"IMDb users have given a \")-15:request_text.index(\"IMDb users have given a \")-1].strip()).replace(\",\",\"\"))) < vote_threshold:\n",
    "        return [0,0,0,0,0,0,0,0,0,0], 0.0\n",
    "\n",
    "    star_votes = re.findall(\"<div class=\\\"leftAligned\\\">(.*?)</div>\", request_text)\n",
    "    rating = re.findall(\"span class=\\\"ipl-rating-star__rating\\\">(.*?)</span>\", request_text)\n",
    "    stars = [int(vote.replace(\",\",\"\")) for vote in star_votes[1:11]]\n",
    "    \n",
    "    return stars, float(rating[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 second for a link\n",
    "stars, rating = get_votes(\"https://www.imdb.com/title/tt0068646/ratings/?ref_=tt_ov_rt\", vote_threshold=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dataset(dataset, start=0, end=0, zip=1):\n",
    "    for i in range(start, end):\n",
    "        try:\n",
    "            stars, rating = get_votes(dataset.iloc[i][\"rating link\"])\n",
    "            dataset.loc[i,[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]] = stars\n",
    "            dataset.loc[i,[\"Rating\",\"Votes\"]] = rating, sum(stars)\n",
    "        except:\n",
    "            pass\n",
    "        if i % 100 == 0:\n",
    "            print(i,\". movie done between \",start,\"-\",end, sep=\"\")\n",
    "\n",
    "    if zip:\n",
    "        print(end,\". movie done between \",start,\"-\",end, sep=\"\")\n",
    "        dataset[:end].to_csv(\"movie_data_at_\"+str(start)+\"_\"+str(end)+\".csv\", index=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"movie_data_at_5000_6000.csv\")\n",
    "dataset = fill_dataset(dataset, start=6000, end=7000, zip=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging movie and box office datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_movies_with_boxoffices(movie_csv_path, how_to_merge):\n",
    "    import pandas as pd\n",
    "    dataset = pd.read_csv(movie_csv_path)\n",
    "    dataset = dataset[~dataset[\"1\"].isnull()]\n",
    "    dataset = dataset[dataset[\"Votes\"]>0]\n",
    "    dataset[\"Title-Year\"] = dataset[\"Year\"].astype(str) + \" \" + dataset[\"Title\"]\n",
    "\n",
    "    movie_box_dataset = pd.read_csv(\"year_movie_worldwide_box.csv\")\n",
    "    movie_box_dataset.columns =  [\"Year\", \"Title\", \"WorldwideBox Office\"]\n",
    "    movie_box_dataset[\"Title-Year\"] = movie_box_dataset[\"Year\"].astype(int).astype(str) + \" \" + movie_box_dataset[\"Title\"]\n",
    "\n",
    "    including_movies = movie_box_dataset[movie_box_dataset[\"Title-Year\"].isin(list(dataset[\"Title-Year\"]))]\n",
    "    merge = pd.merge(dataset, including_movies[[\"Title-Year\",\"WorldwideBox Office\"]], on=\"Title-Year\", how=how_to_merge)\n",
    "    return merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge_movies_with_boxoffices(\"informative_movie_data.csv\", \"outer\")\n",
    "merge.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revenue(link):\n",
    "    import requests\n",
    "    import numpy as np\n",
    "    text = requests.get(link).text\n",
    "    if \"<span class=\\\"ipc-metadata-list-item__label\\\">Gross worldwide</span>\" in text:\n",
    "        revenue_part = text[text.index(\"<span class=\\\"ipc-metadata-list-item__label\\\">Gross worldwide</span>\"):]\n",
    "        revenue = int(revenue_part[revenue_part.index(\"$\")+1:].split(\"</span>\")[0].replace(\",\",\"\"))\n",
    "        return revenue\n",
    "    raise Exception(\"cant find worldwide gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_revenues(dataset, start=0, end=0, zip=1):\n",
    "    from datetime import datetime\n",
    "    import requests\n",
    "\n",
    "    for i in range(start, end):\n",
    "        try:\n",
    "            revenue = get_revenue(dataset.iloc[i][\"imdb_url\"])\n",
    "            dataset.loc[i,\"WorldwideBox Office\"] = revenue\n",
    "        except:\n",
    "            pass\n",
    "        if i % 100 == 0:\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), \" ..... \", i,\". movie done between \",start,\"-\",end, sep=\"\")\n",
    "            if i%1000 == 0 and zip:\n",
    "                dataset[:end].to_csv(\"movie_revenue_data_at_\"+str(start)+\"_\"+str(end)+\".csv\", index=False)\n",
    "\n",
    "    dataset.to_csv(\"movie_revenue_data_all.csv\", index=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_revenue_from_wikipedia(title_year):\n",
    "    import requests\n",
    "    year, title = title_year[:title_year.index(\" \")], title_year[title_year.index(\" \")+1:]\n",
    "\n",
    "    try:\n",
    "        text = requests.get(\"https://en.wikipedia.org/wiki/\"+title.replace(\" \",\"_\")).text\n",
    "        a = text[text.index(\"Box office</th>\"):]\n",
    "        revenue = a[a.index(\"style=\\\"white-space: nowrap\\\">\") + len(\"style=\\\"white-space: nowrap\\\">\"): a.index(\"</span>\")]\n",
    "        return revenue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        text_film = requests.get(\"https://en.wikipedia.org/wiki/\"+title.replace(\" \",\"_\")+\"_(film)\").text\n",
    "        a = text_film[text_film.index(\"Box office</th>\"):]\n",
    "        revenue = a[a.index(\"style=\\\"white-space: nowrap\\\">\") + len(\"style=\\\"white-space: nowrap\\\">\"): a.index(\"</span>\")]\n",
    "        return revenue\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        text_film_year = requests.get(\"https://en.wikipedia.org/wiki/\"+title.replace(\" \",\"_\")+\"_(\"+year+\"_film)\").text\n",
    "        a = text_film_year[text_film_year.index(\"Box office</th>\"):]\n",
    "        revenue = a[a.index(\"style=\\\"white-space: nowrap\\\">\") + len(\"style=\\\"white-space: nowrap\\\">\"): a.index(\"</span>\")]\n",
    "        return revenue\n",
    "    except:\n",
    "        pass\n",
    "    raise Exception(\"cant find worldwide gross\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_revenues_from_wikipedia(dataset, indices, start=0, end=0, zip=1):\n",
    "    from datetime import datetime\n",
    "    import requests\n",
    "\n",
    "    for i in indices:\n",
    "        try:\n",
    "            revenue = get_revenue_from_wikipedia(dataset.iloc[i][\"Title-Year\"])\n",
    "            dataset.loc[i,\"WorldwideBox Office\"] = revenue\n",
    "        except:\n",
    "            pass\n",
    "        if i % 100 == 0:\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), \" ..... \", i,\". movie done between \",start,\"-\",end, sep=\"\")\n",
    "            if i%1000 == 0 and zip:\n",
    "                dataset[:end].to_csv(\"movie_revenue_data_at_\"+str(start)+\"_\"+str(end)+\".csv\", index=False)\n",
    "\n",
    "    dataset.to_csv(\"movie_revenue_data_all.csv\", index=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"movie_revenue_data_all.csv\")\n",
    "data = pd.DataFrame(data)\n",
    "data['WorldwideBox Office'] = data['WorldwideBox Office'].astype('str')\n",
    "data['WorldwideBox Office'] = data['WorldwideBox Office'].str.replace(',', '')\n",
    "data['WorldwideBox Office'] = pd.to_numeric(data['WorldwideBox Office'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       76019048.0\n",
       "1       71609321.0\n",
       "2       21413502.0\n",
       "3       33461269.0\n",
       "4        7331647.0\n",
       "           ...    \n",
       "7620     4961424.0\n",
       "7621     8399765.0\n",
       "7622     1351662.0\n",
       "7623      522938.0\n",
       "7624     4588389.0\n",
       "Name: WorldwideBox Office, Length: 7625, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WorldwideBox Office']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10afed49a6762d7df4ebe8287b2b982d81e7226d8e1c4032e987e1476c562bb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
