{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(X_valid, y_valid, prediction, model):\n",
    "    from datetime import datetime\n",
    "    date = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_valid, prediction, squared=True)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rmse = mean_squared_error(y_valid, prediction ,squared=False)\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    mae = mean_absolute_error(y_valid, prediction)\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(y_valid, prediction)\n",
    "\n",
    "    #Adjusted R Squared:\n",
    "    adjusted_r2 = 1-(1-r2_score(y_valid, prediction))*((len(y_valid))-1)/((len(y_valid))-len(X_valid.columns))\n",
    "\n",
    "    log = str(date) + \"  model:\" + model + \"\\nMSE: \" + str(mse) + \"\\nRMSE: \" + str(rmse) + \"\\nMAE: \" + str(mae) + \"\\nR2: \" + str(r2) + \"\\nAdjustedR2: \" + str(adjusted_r2) + \"\\n\\n\"\n",
    "    with open(\"model_logs.txt\", \"a\") as file_object:\n",
    "        file_object.write(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Model methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = pd.read_csv(\"movie_revenue_data.csv\")\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    years = (data[\"Year\"]).unique()\n",
    "    years.sort()\n",
    "    revenues = []\n",
    "    for year in (data[\"Year\"]).unique():\n",
    "        revenues.append(data[data[\"Year\"] == year][\"WorldwideBox Office\"].mean())\n",
    "\n",
    "    scaled_revenues = np.array(revenues)/1e8\n",
    "    year_revenue_dict = {years[i]: scaled_revenues[i] for i in range(len(years))}\n",
    "    data['Year'] = data['Year'].map(year_revenue_dict)\n",
    "    data[\"Rating\"] = data[\"Rating\"]/10\n",
    "    data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']] = np.log2(data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']])\n",
    "    data=data[data[\"WorldwideBox Office\"]>16.609640474436812].reset_index(drop=True) # movies with revenue<100.000\n",
    "    data=data[data[\"WorldwideBox Office\"]<30].reset_index(drop=True)\n",
    "\n",
    "    import math \n",
    "    SEED = int(math.sqrt(201401004 + 191401009))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(['Title','WorldwideBox Office'], axis=1), data['WorldwideBox Office'], test_size=0.10, random_state=SEED)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1111111111111111, random_state=SEED)\n",
    "\n",
    "    from pickle import dump\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.fit_transform(X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    dump(min_max_scaler, open('MinMaxScaler.pickle', 'wb'))\n",
    "\n",
    "    return data, X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_wo_log():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = pd.read_csv(\"movie_revenue_data.csv\")\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    years = (data[\"Year\"]).unique()\n",
    "    years.sort()\n",
    "    revenues = []\n",
    "    for year in (data[\"Year\"]).unique():\n",
    "        revenues.append(data[data[\"Year\"] == year][\"WorldwideBox Office\"].mean())\n",
    "\n",
    "    scaled_revenues = np.array(revenues)/1e8\n",
    "    year_revenue_dict = {years[i]: scaled_revenues[i] for i in range(len(years))}\n",
    "    data['Year'] = data['Year'].map(year_revenue_dict)\n",
    "    data[\"Rating\"] = data[\"Rating\"]/10\n",
    "    data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']] = np.log2(data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']])\n",
    "\n",
    "    data=data[data[\"WorldwideBox Office\"]>16.609640474436812].reset_index(drop=True) # movies with revenue<100.000\n",
    "    data=data[data[\"WorldwideBox Office\"]<30].reset_index(drop=True)\n",
    "    min_log_revenue = data[\"WorldwideBox Office\"].min()\n",
    "    data[\"WorldwideBox Office\"] = 2**(data[\"WorldwideBox Office\"] - min_log_revenue)\n",
    "\n",
    "    import math \n",
    "    SEED = int(math.sqrt(201401004 + 191401009))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(['Title','WorldwideBox Office'], axis=1), data['WorldwideBox Office'], test_size=0.10, random_state=SEED)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1111111111111111, random_state=SEED)\n",
    "\n",
    "    from pickle import dump\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.fit_transform(X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    dump(min_max_scaler, open('MinMaxScaler.pickle', 'wb'))\n",
    "\n",
    "    return data, X_train, X_validation, X_test, y_train, y_validation, y_test, 2**min_log_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(prediction, y_valid):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    pred_data = pd.DataFrame({'normalized revenue': np.hstack((y_valid, prediction)), 'true or pred': np.hstack(([\"true\"]*len(y_valid) , [\"pred\"]*len(prediction)))})\n",
    "    pred_data.sort_values(by=['normalized revenue'], ascending = True, inplace = True)\n",
    "    pred_data_T = pred_data[pred_data[\"true or pred\"] == \"true\"]\n",
    "    pred_data_T.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    pred_data_P = pred_data[pred_data[\"true or pred\"] == \"pred\"]\n",
    "    pred_data_P.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    plot_data = pd.concat([pred_data_T, pred_data_P])\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(50,20)})\n",
    "    sns.scatterplot(data=plot_data,\n",
    "                    x=\"plot index\",\n",
    "                    y=\"normalized revenue\",\n",
    "                    hue=\"true or pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_wo_log(prediction, y_valid, y_min):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    prediction[prediction<0] = 1/y_min\n",
    "    prediction = np.log2(prediction*y_min)\n",
    "    y_valid = np.log2(y_valid*y_min)\n",
    "\n",
    "    pred_data = pd.DataFrame({'normalized revenue': np.hstack((y_valid, prediction)), 'true or pred': np.hstack(([\"true\"]*len(y_valid) , [\"pred\"]*len(prediction)))})\n",
    "    pred_data.sort_values(by=['normalized revenue'], ascending = True, inplace = True)\n",
    "    pred_data_T = pred_data[pred_data[\"true or pred\"] == \"true\"]\n",
    "    pred_data_T.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    pred_data_P = pred_data[pred_data[\"true or pred\"] == \"pred\"]\n",
    "    pred_data_P.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    plot_data = pd.concat([pred_data_T, pred_data_P])\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(50,20)})\n",
    "    sns.scatterplot(data=plot_data,\n",
    "                    x=\"plot index\",\n",
    "                    y=\"normalized revenue\",\n",
    "                    hue=\"true or pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression without log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_wo_log()\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    LR = pickle.load(open('LR_without_log.pickle', 'rb'))\n",
    "except:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    LR = LinearRegression().fit(X_train, y_train)\n",
    "    import pickle\n",
    "    pickle.dump(LR, open('LR_without_log.pickle', 'wb'))\n",
    "\n",
    "print(\"LinearRegression score on train:\", LR.score(X_train, y_train))\n",
    "\n",
    "LR_validation_prediction = LR.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, LR_validation_prediction, \"LR without log\")\n",
    "plot_pred_wo_log(LR_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with log and sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    LR = pickle.load(open('LR_with_log_and_weight.pickle', 'rb'))\n",
    "except:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    LR = LinearRegression().fit(X_train, y_train, sample_weight=y_train.astype(int) - y_train.astype(int).min())\n",
    "    import pickle\n",
    "    pickle.dump(LR, open('LR_with_log_and_weight.pickle', 'wb'))\n",
    "\n",
    "print(\"LinearRegression score on train:\", LR.score(X_train, y_train))\n",
    "\n",
    "LR_validation_prediction = LR.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, LR_validation_prediction, \"LR with log and sample weight\")\n",
    "plot_pred(LR_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    LR = pickle.load(open('LR_with_log.pickle', 'rb'))\n",
    "except:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    LR = LinearRegression().fit(X_train, y_train)\n",
    "    import pickle\n",
    "    pickle.dump(LR, open('LR_with_log.pickle', 'wb'))\n",
    "\n",
    "print(\"LinearRegression score on train:\", LR.score(X_train, y_train))\n",
    "log_metrics(X_validation, y_validation, LR_validation_prediction, \"LR with log\")\n",
    "plot_pred(LR_validation_prediction, y_validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector regression without log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    SVR_grid = pickle.load(open('SVR_grid_without_log.pickle', 'rb'))\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "except:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVR\n",
    "    grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            \"kernel\": ['poly', 'rbf'],\n",
    "            \"gamma\": [0.1, 1, 5, 10],\n",
    "            \"degree\": [2, 3, 4],\n",
    "            \"max_iter\": [4000, 5000, 6000]\n",
    "            }\n",
    "    SVR = SVR()\n",
    "    SVR_grid = GridSearchCV(SVR, grid, refit = True, n_jobs=-1, cv=10)\n",
    "    SVR_grid.fit(X_train, y_train)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(SVR_grid, open('SVR_grid_without_log.pickle', 'wb'))\n",
    "\n",
    "SVR_best_validation_prediction = SVR_best.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, SVR_best_validation_prediction, \"SVR without log\")\n",
    "plot_pred_wo_log(SVR_best_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector regression with log and sample weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    SVR_grid = pickle.load(open('SVR_grid_with_log_and_weight.pickle', 'rb'))\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "except:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVR\n",
    "    grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            \"kernel\": ['poly', 'rbf'],\n",
    "            \"gamma\": [0.1, 1, 5, 10],\n",
    "            \"degree\": [2, 3, 4],\n",
    "            \"max_iter\": [4000, 5000, 6000]\n",
    "            }\n",
    "    SVR = SVR()\n",
    "    SVR_grid = GridSearchCV(SVR, grid, refit = True, n_jobs=-1, cv=10)\n",
    "    SVR_grid.fit(X_train, y_train, sample_weight=y_train.astype(int) - y_train.astype(int).min())\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(SVR_grid, open('SVR_grid_with_log_and_weight.pickle', 'wb'))\n",
    "\n",
    "SVR_best_validation_prediction = SVR_best.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, SVR_best_validation_prediction, \"SVR with log and sample weight\")\n",
    "plot_pred(SVR_best_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector regression with log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    SVR_grid = pickle.load(open('SVR_grid_with_log.pickle', 'rb'))\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "except:\n",
    "    import math \n",
    "    SEED = int(math.sqrt(201401004 + 191401009))\n",
    "    data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVR\n",
    "    grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            \"kernel\": ['poly', 'rbf'],\n",
    "            \"gamma\": [0.1, 1, 5, 10],\n",
    "            \"degree\": [2, 3, 4],\n",
    "            \"max_iter\": [4000, 5000, 6000]\n",
    "            }\n",
    "    SVR = SVR()\n",
    "    SVR_grid = GridSearchCV(SVR, grid, refit = True, n_jobs=-1, cv=10)\n",
    "    SVR_grid.fit(X_train, y_train)\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", SVR_grid.best_params_)\n",
    "    print(\"Support Vector Machine score on train:\", SVR_grid.best_score_)\n",
    "    SVR_best = SVR_grid.best_estimator_\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(SVR_grid, open('SVR_grid_with_log.pickle', 'wb'))\n",
    "\n",
    "SVR_best_validation_prediction = SVR_best.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, SVR_best_validation_prediction, \"SVR with log\")\n",
    "plot_pred(SVR_best_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data()\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    RFR_grid = pickle.load(open('RFR_grid.pickle', 'rb'))\n",
    "    print(\"tuned hpyerparameters :(best parameters) \", RFR_grid.best_params_)\n",
    "    print(\"RandomForestRegressor score on train:\", RFR_grid.best_score_)\n",
    "    RFR_best = RFR_grid.best_estimator_\n",
    "except:\n",
    "    try:\n",
    "        import pickle\n",
    "        RFR_best = pickle.load(open('best_RFR.pickle', 'rb'))\n",
    "    \n",
    "    except:\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        \n",
    "        grid = {\n",
    "                \"n_estimators\": [300, 400, 500],\n",
    "                'max_depth': [10, 15, 20],\n",
    "                \"criterion\": ['squared_error', 'absolute_error'],\n",
    "                \"max_samples\": [0.5, 0.75,  1],\n",
    "                \"min_samples_split\": [2, 4, 6],\n",
    "                \"max_features\": [1, 3, 5, 7],\n",
    "                }\n",
    "\n",
    "        RFR = RandomForestRegressor(random_state=SEED, bootstrap=True, oob_score=True, n_jobs=-1)\n",
    "\n",
    "        RFR_grid = GridSearchCV(RFR, grid, refit = True, n_jobs=-1, cv=10)\n",
    "        RFR_grid.fit(X_train, y_train)\n",
    "        print(\"tuned hpyerparameters :(best parameters) \", RFR_grid.best_params_)\n",
    "        print(\"RandomForestRegressor score on train:\", RFR_grid.best_score_)\n",
    "        RFR_best = RFR_grid.best_estimator_\n",
    "        \n",
    "        import pickle\n",
    "        pickle.dump(RFR_grid, open('RFR_grid.pickle', 'wb'))\n",
    "\n",
    "RFR_best_validation_prediction = RFR_best.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, RFR_best_validation_prediction, \"RF with log\")\n",
    "plot_pred(RFR_best_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_for_NN(prediction, y_valid):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    NN_pred_data = pd.DataFrame({'normalized revenue': np.hstack((y_valid, [p[0] for p in prediction])), 'true or pred': np.hstack(([\"true\"]*len(y_valid) , [\"pred\"]*len(prediction)))})\n",
    "    NN_pred_data.sort_values(by=['normalized revenue'], ascending = True, inplace = True)\n",
    "    NN_pred_data_T = NN_pred_data[NN_pred_data[\"true or pred\"] == \"true\"]\n",
    "    NN_pred_data_T.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_pred_data_P = NN_pred_data[NN_pred_data[\"true or pred\"] == \"pred\"]\n",
    "    NN_pred_data_P.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_plot_data = pd.concat([NN_pred_data_T, NN_pred_data_P])\n",
    "    sns.set(rc={'figure.figsize':(50,20)})\n",
    "    sns.scatterplot(data=NN_plot_data,\n",
    "                    x=\"plot index\",\n",
    "                    y=\"normalized revenue\",\n",
    "                    hue=\"true or pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_for_NN_wo_log(prediction, y_valid, y_min):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    prediction = np.array([p[0] for p in prediction])\n",
    "    prediction[prediction<0] = 1/y_min\n",
    "    prediction = np.log2(prediction*y_min)\n",
    "    y_valid = np.log2(y_valid*y_min)\n",
    "\n",
    "    NN_pred_data = pd.DataFrame({'normalized revenue': np.hstack((y_valid, prediction)), 'true or pred': np.hstack(([\"true\"]*len(y_valid) , [\"pred\"]*len(prediction)))})\n",
    "    NN_pred_data.sort_values(by=['normalized revenue'], ascending = True, inplace = True)\n",
    "    NN_pred_data_T = NN_pred_data[NN_pred_data[\"true or pred\"] == \"true\"]\n",
    "    NN_pred_data_T.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_pred_data_P = NN_pred_data[NN_pred_data[\"true or pred\"] == \"pred\"]\n",
    "    NN_pred_data_P.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_plot_data = pd.concat([NN_pred_data_T, NN_pred_data_P])\n",
    "    sns.set(rc={'figure.figsize':(50,20)})\n",
    "    sns.scatterplot(data=NN_plot_data,\n",
    "                    x=\"plot index\",\n",
    "                    y=\"normalized revenue\",\n",
    "                    hue=\"true or pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_for_NN_with_interval(prediction, y_valid, y_min):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    prediction = np.array([p[0] for p in prediction])\n",
    "    prediction[prediction<0] = 1/y_min\n",
    "    prediction = prediction*y_min\n",
    "    y_valid = y_valid*y_min\n",
    "    lower_prediction = 2**(np.log2(prediction)-1)\n",
    "    upper_prediction = 2**(np.log2(prediction)+1)\n",
    "\n",
    "    NN_pred_data = pd.DataFrame({'normalized revenue': np.hstack((y_valid, lower_prediction, prediction, upper_prediction)), 'true or pred': np.hstack(([\"true\"]*len(y_valid), [\"lower_pred\"]*len(lower_prediction), [\"pred\"]*len(prediction), [\"upper_pred\"]*len(upper_prediction)))})\n",
    "    NN_pred_data.sort_values(by=['normalized revenue'], ascending = True, inplace = True)\n",
    "    NN_pred_data_T = NN_pred_data[NN_pred_data[\"true or pred\"] == \"true\"]\n",
    "    NN_pred_data_T.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "\n",
    "    NN_pred_data_LP = NN_pred_data[NN_pred_data[\"true or pred\"] == \"lower_pred\"]\n",
    "    NN_pred_data_LP.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_pred_data_P = NN_pred_data[NN_pred_data[\"true or pred\"] == \"pred\"]\n",
    "    NN_pred_data_P.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "    NN_pred_data_UP = NN_pred_data[NN_pred_data[\"true or pred\"] == \"upper_pred\"]\n",
    "    NN_pred_data_UP.insert(0, \"plot index\", list(range(len(y_valid))))\n",
    "\n",
    "    NN_plot_data = pd.concat([NN_pred_data_T, NN_pred_data_LP, NN_pred_data_P, NN_pred_data_UP])\n",
    "    sns.set(rc={'figure.figsize':(50,20)})\n",
    "    c = sns.lineplot(data=NN_plot_data,\n",
    "                    x=\"plot index\",\n",
    "                    y=\"normalized revenue\",\n",
    "                    hue=\"true or pred\",\n",
    "                    estimator=None,\n",
    "                    linewidth=10)\n",
    "\n",
    "    line = c.get_lines()\n",
    "    plt.fill_between(line[0].get_xdata(), line[1].get_ydata(), line[3].get_ydata(), color='green', alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_for_NN_wo_log():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = pd.read_csv(\"movie_revenue_data.csv\")\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    years = (data[\"Year\"]).unique()\n",
    "    years.sort()\n",
    "    revenues = []\n",
    "    for year in (data[\"Year\"]).unique():\n",
    "        revenues.append(data[data[\"Year\"] == year][\"WorldwideBox Office\"].mean())\n",
    "\n",
    "\n",
    "\n",
    "    scaled_revenues = np.array(revenues)/1e8\n",
    "    year_revenue_dict = {years[i]: scaled_revenues[i] for i in range(len(years))}\n",
    "    data['Year'] = data['Year'].map(year_revenue_dict)\n",
    "    data[\"Rating\"] = data[\"Rating\"]/10\n",
    "\n",
    "    data[\"1%\"] = data[\"1\"] / data[\"Votes\"]\n",
    "    data[\"2%\"] = data[\"2\"] / data[\"Votes\"]\n",
    "    data[\"3%\"] = data[\"3\"] / data[\"Votes\"]\n",
    "    data[\"4%\"] = data[\"4\"] / data[\"Votes\"]\n",
    "    data[\"5%\"] = data[\"5\"] / data[\"Votes\"]\n",
    "    data[\"6%\"] = data[\"6\"] / data[\"Votes\"]\n",
    "    data[\"7%\"] = data[\"7\"] / data[\"Votes\"]\n",
    "    data[\"8%\"] = data[\"8\"] / data[\"Votes\"]\n",
    "    data[\"9%\"] = data[\"9\"] / data[\"Votes\"]\n",
    "    data[\"10%\"] = data[\"10\"] / data[\"Votes\"]\n",
    "\n",
    "    data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']] = np.log2(data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']])\n",
    "    data=data[data[\"WorldwideBox Office\"]>16.609640474436812].reset_index(drop=True) # movies with revenue<100.000\n",
    "    data=data[data[\"WorldwideBox Office\"]<30].reset_index(drop=True)\n",
    "    min_log_revenue = data[\"WorldwideBox Office\"].min()\n",
    "    data[\"WorldwideBox Office\"] = 2**(data[\"WorldwideBox Office\"] - min_log_revenue)\n",
    "\n",
    "    import math \n",
    "    SEED = int(math.sqrt(201401004 + 191401009))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(['Title','WorldwideBox Office'], axis=1), data['WorldwideBox Office'], test_size=0.10, random_state=SEED)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1111111111111111, random_state=SEED)\n",
    "\n",
    "    from pickle import dump\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.fit_transform(X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    dump(min_max_scaler, open('MinMaxScaler.pickle', 'wb'))\n",
    "\n",
    "    return data, X_train, X_validation, X_test, y_train, y_validation, y_test, 2**min_log_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_for_NN():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    data = pd.read_csv(\"movie_revenue_data.csv\")\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    years = (data[\"Year\"]).unique()\n",
    "    years.sort()\n",
    "    revenues = []\n",
    "    for year in (data[\"Year\"]).unique():\n",
    "        revenues.append(data[data[\"Year\"] == year][\"WorldwideBox Office\"].mean())\n",
    "\n",
    "\n",
    "\n",
    "    scaled_revenues = np.array(revenues)/1e8\n",
    "    year_revenue_dict = {years[i]: scaled_revenues[i] for i in range(len(years))}\n",
    "    data['Year'] = data['Year'].map(year_revenue_dict)\n",
    "    data[\"Rating\"] = data[\"Rating\"]/10\n",
    "\n",
    "    data[\"1%\"] = data[\"1\"] / data[\"Votes\"]\n",
    "    data[\"2%\"] = data[\"2\"] / data[\"Votes\"]\n",
    "    data[\"3%\"] = data[\"3\"] / data[\"Votes\"]\n",
    "    data[\"4%\"] = data[\"4\"] / data[\"Votes\"]\n",
    "    data[\"5%\"] = data[\"5\"] / data[\"Votes\"]\n",
    "    data[\"6%\"] = data[\"6\"] / data[\"Votes\"]\n",
    "    data[\"7%\"] = data[\"7\"] / data[\"Votes\"]\n",
    "    data[\"8%\"] = data[\"8\"] / data[\"Votes\"]\n",
    "    data[\"9%\"] = data[\"9\"] / data[\"Votes\"]\n",
    "    data[\"10%\"] = data[\"10\"] / data[\"Votes\"]\n",
    "\n",
    "    data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']] = np.log2(data[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'WorldwideBox Office']])\n",
    "    data=data[data[\"WorldwideBox Office\"]>16.609640474436812].reset_index(drop=True) # movies with revenue<100.000\n",
    "    data=data[data[\"WorldwideBox Office\"]<30].reset_index(drop=True)\n",
    "    \n",
    "    import math \n",
    "    SEED = int(math.sqrt(201401004 + 191401009))\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(['Title','WorldwideBox Office'], axis=1), data['WorldwideBox Office'], test_size=0.10, random_state=SEED)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1111111111111111, random_state=SEED)\n",
    "\n",
    "    from pickle import dump\n",
    "    from sklearn import preprocessing\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.fit_transform(X_train[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_validation[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]= min_max_scaler.transform(X_test[['Votes', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']])\n",
    "    dump(min_max_scaler, open('MinMaxScaler.pickle', 'wb'))\n",
    "\n",
    "    return data, X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow import keras;\n",
    "\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential([Input(shape=(13,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "\"\"\" KERAS / TENSORFLOW\n",
    "https://faroit.com/keras-docs/2.1.3/models/sequential/\n",
    "\n",
    "https://faroit.com/keras-docs/2.1.3/\n",
    "https://keras.io/getting_started/\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/\n",
    "https://www.tensorflow.org/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" SAVE & LOAD WEIGHTS\n",
    "save_weights(\n",
    "    filepath, overwrite=True, save_format=None, options=None\n",
    ")\n",
    "\n",
    "load_weights(\n",
    "    filepath, by_name=False, skip_mismatch=False, options=None\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=32, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN14_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN14_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN14 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"tanh\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint(filepath = \"kerasNN14_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN14_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN14 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"tanh\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN14_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN14_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN14 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN16_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN16_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN16 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"tanh\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN16_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN16_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN16 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"tanh\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN16_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN16_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN16 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN19_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN19_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN19 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN19_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN19_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN19 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN19_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN19_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN19 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN20_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN20_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN20 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN20_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN20_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN20 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN20_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN20_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=4, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN20 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN23_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN23_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN23 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN23_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN23_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN23 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN23_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN23_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN23 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN24_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN24_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN24 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN24_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN24_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN24 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN24_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN24_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN24 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN25_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN25_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN25 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN25_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN25_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN25 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN25_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN25_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN25 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5, patience=10, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras26-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-2_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-2_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-2 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-2_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-2_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-2 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-2_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-2_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-2 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kerasN26-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-3_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-3_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-3 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-3_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-3_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-3 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN26-3_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN26-3_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN26-3 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras27-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27-2_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27-2_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27-2 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27-2_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27-2_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27-2 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN27-2_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=15, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN27-2_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN27-2 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN28_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=75, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN28_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN28 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN28_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=75, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN28_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN28 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN28_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=75, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.25, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN28_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=7, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN28 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN29_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN29_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN29 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"], sample_weight_mode=\"temporal\", weighted_metrics=[])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN29_with_sample_weight.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN29_with_sample_weight.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks, sample_weight=y_train.astype(int) - y_train.astype(int).min()+1)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN29 with log and sample weight\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test = set_data_for_NN()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.1, seed=SEED))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN29_with_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=50, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.2, patience=30, verbose=1, mode=\"auto\", min_delta=0.001, cooldown=7, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN29_with_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN29 with log\")\n",
    "plot_pred_for_NN(NN_validation_prediction, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN30_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN30_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN30 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"sigmoid\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(128, activation=\"tanh\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(13, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\", loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNN31_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "#tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "#tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.3, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)\n",
    "]\n",
    "try:\n",
    "    model.load_weights('kerasNN31_wo_log.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=12, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"NN31 without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras tuner1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(96, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, seed=SEED))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(192, activation=\"relu\"))\n",
    "model.add(Dropout(0.4, seed=SEED))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNNtuner_wo_log-001-24.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=100, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)]\n",
    "\n",
    "try:\n",
    "    model.load_weights('kerasNNtuner_wo_log-001-24.h5')\n",
    "except:\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=24, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"kerasNNtuner without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_for_NN_with_interval(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras-Tuner  \n",
    "#### https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential([Input(shape=(23,))])\n",
    "\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer1', min_value=32, max_value=64, step=32), activation='sigmoid'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer2', min_value=32, max_value=128, step=32), activation='tanh'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer3', min_value=64, max_value=128, step=32), activation='relu'))\n",
    "    Dropout(rate = hp.Float(\"dropout layer1\", min_value = 0.0, max_value=0.3, step=0.1))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer4', min_value=64, max_value=256, step=32), activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer5', min_value=128, max_value=265, step=32), activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer6', min_value=128, max_value=256, step=32), activation='relu'))\n",
    "    Dropout(rate = hp.Float(\"dropout layer2\", min_value = 0.0, max_value=0.3, step=0.1))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer7', min_value=64, max_value=128, step=32), activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer8', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "    model.add(keras.layers.Dense(units=hp.Int('hidden layer9', min_value=16, max_value=64, step=16), activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.001, 0.01])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate), loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "    return model\n",
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNNdeepertuner_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=30, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=7, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tuner = kt.Hyperband(model_builder, objective='val_loss', max_epochs=200, factor=2, seed=SEED)\n",
    "    tuner.search_space_summary(extended=True)\n",
    "    data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "    tuner.search(X_train, y_train, epochs=200, validation_split=0.1, callbacks=my_callbacks)\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    print(\"Hyperband Best Parameters\")\n",
    "    print(best_hps[\"hidden layer1\"])\n",
    "    print(best_hps[\"hidden layer2\"])\n",
    "    print(best_hps[\"hidden layer3\"])\n",
    "    print(best_hps[\"dropout layer1\"])\n",
    "    print(best_hps[\"hidden layer4\"])\n",
    "    print(best_hps[\"hidden layer5\"])\n",
    "    print(best_hps[\"hidden layer6\"])\n",
    "    print(best_hps[\"dropout layer2\"])\n",
    "    print(best_hps[\"hidden layer7\"])\n",
    "    print(best_hps[\"hidden layer8\"])\n",
    "    print(best_hps[\"hidden layer9\"])\n",
    "    print(best_hps[\"learning rate\"])\n",
    "except:\n",
    "    print(\"hata verdi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tuner = kt.RandomSearch(model_builder, objective=\"val_loss\", max_trials=10,seed=SEED, directory=\"/home/meric/Masast/Code/470/github/movie-revenue-predictio/oracle_dir/Random\",)\n",
    "    tuner.search_space_summary(extended=True)\n",
    "    data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "    tuner.search(X_train, y_train, epochs=100, validation_split=0.1, callbacks=my_callbacks)\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    print(\"RandomSearch Best Parameters\")\n",
    "    print(best_hps[\"hidden layer1\"])\n",
    "    print(best_hps[\"hidden layer2\"])\n",
    "    print(best_hps[\"hidden layer3\"])\n",
    "    print(best_hps[\"dropout layer1\"])\n",
    "    print(best_hps[\"hidden layer4\"])\n",
    "    print(best_hps[\"hidden layer5\"])\n",
    "    print(best_hps[\"hidden layer6\"])\n",
    "    print(best_hps[\"dropout layer2\"])\n",
    "    print(best_hps[\"hidden layer7\"])\n",
    "    print(best_hps[\"hidden layer8\"])\n",
    "    print(best_hps[\"hidden layer9\"])\n",
    "    print(best_hps[\"learning rate\"])\n",
    "except:\n",
    "    print(\"hata verdi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tuner = kt.BayesianOptimization(model_builder,objective=\"val_loss\", max_trials=10,seed=SEED, directory=\"/home/meric/Masast/Code/470/github/movie-revenue-predictio/oracle_dir/Bayesian\",)\n",
    "    tuner.search_space_summary(extended=True)\n",
    "    data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "    tuner.search(X_train, y_train, epochs=100, validation_split=0.1, callbacks=my_callbacks)\n",
    "    # Get the optimal hyperparameters\n",
    "    best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "    print(\"BayesianOptimization Best Parameters\")\n",
    "    print(best_hps[\"hidden layer1\"])\n",
    "    print(best_hps[\"hidden layer2\"])\n",
    "    print(best_hps[\"hidden layer3\"])\n",
    "    print(best_hps[\"dropout layer1\"])\n",
    "    print(best_hps[\"hidden layer4\"])\n",
    "    print(best_hps[\"hidden layer5\"])\n",
    "    print(best_hps[\"hidden layer6\"])\n",
    "    print(best_hps[\"dropout layer2\"])\n",
    "    print(best_hps[\"hidden layer7\"])\n",
    "    print(best_hps[\"hidden layer8\"])\n",
    "    print(best_hps[\"hidden layer9\"])\n",
    "    print(best_hps[\"learning rate\"])\n",
    "except:\n",
    "    print(\"hata verdi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "SEED = int(math.sqrt(201401004 + 191401009))\n",
    "data, X_train, X_validation, X_test, y_train, y_validation, y_test, y_min = set_data_for_NN_wo_log()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from tensorflow.keras.layers import Dense, Dropout;\n",
    "from tensorflow.keras import Input\n",
    "model = Sequential([Input(shape=(23,))])\n",
    "model.add(Dense(hl1, activation=\"sigmoid\"))\n",
    "model.add(Dense(hl2, activation=\"tanh\"))\n",
    "model.add(Dense(hl3, activation=\"tanh\"))\n",
    "model.add(Dropout(do1, seed=SEED))\n",
    "model.add(Dense(hl4, activation=\"relu\"))\n",
    "model.add(Dense(hl5, activation=\"relu\"))\n",
    "model.add(Dense(hl6, activation=\"relu\"))\n",
    "model.add(Dropout(do2, seed=SEED))\n",
    "model.add(Dense(hl7, activation=\"relu\"))\n",
    "model.add(Dense(hl8, activation=\"relu\"))\n",
    "model.add(Dense(hl9, activation=\"relu\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# learning rates: [0.001, 0.01, 0.05, 0.1]\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=[\"mse\", \"mae\"], metrics=[\"mae\", \"mse\"])\n",
    "model.summary()\n",
    "\n",
    "import tensorflow\n",
    "my_callbacks = [\n",
    "tensorflow.keras.callbacks.ModelCheckpoint( filepath = \"kerasNNtuner_wo_log.h5\", monitor = \"val_loss\", verbose=1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq = \"epoch\"),\n",
    "tensorflow.keras.callbacks.EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=100, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True),\n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.1, patience=10, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=5, min_lr=0)]\n",
    "\n",
    "try:\n",
    "    model.load_weights('kerasNNtuner_wo_log.h5')\n",
    "except:\n",
    "    # batch_sizes = [8,16,24]\n",
    "    model.fit(X_train, y_train, epochs=300, batch_size=24, verbose=1, validation_split=0.1, workers=16, callbacks=my_callbacks)\n",
    "\n",
    "print(\"Evaluate on validation data\")\n",
    "results = model.evaluate(X_validation , y_validation, batch_size=12, workers=16)\n",
    "print(\"validation loss, validation mae,  validation mse:\", results)\n",
    "NN_validation_prediction = model.predict(X_validation)\n",
    "log_metrics(X_validation, y_validation, NN_validation_prediction, \"kerasNNtuner without log\")\n",
    "plot_pred_for_NN_wo_log(NN_validation_prediction, y_validation, y_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Best parameters\n",
    "hidden layer1: 32\n",
    "hidden layer2: 96\n",
    "dropout layer1: 0.1\n",
    "hidden layer3: 128\n",
    "hidden layer4: 192\n",
    "dropout layer2: 0.30000000000000004\n",
    "hidden layer5: 128\n",
    "hidden layer6: 64\n",
    "hidden layer7: 32\n",
    "learning rate: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for p,y in zip([pred[0]*y_min for pred in NN_validation_prediction], y_validation*y_min):\n",
    "    if abs(p-y) == abs([pred[0]*y_min for pred in NN_validation_prediction]- y_validation*y_min).max():\n",
    "        print(p, y, abs(y-p), np.log2(p), np.log2(y), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('470env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "852b83a69ba2ac7177cbe57ebf84874f55f6dbc80009fc6f623a4bed5389248a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
